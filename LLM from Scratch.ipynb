{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a892bafd",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7726dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176892b",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c88f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f69509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72a08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren.\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Before trainin, we are just testing the model with a few tokens\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(f\"Output text: {token_ids_to_text(token_ids, tokenizer)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce61857",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f929ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "# First 100 characters\n",
    "print(text_data[:99])\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff27256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f6f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9415a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5402bed",
   "metadata": {},
   "source": [
    "### Training the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8998eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(\n",
    "    device\n",
    ")  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae11760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de70a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Training completed in 1.18 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aec432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced1f1b",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7273582",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
