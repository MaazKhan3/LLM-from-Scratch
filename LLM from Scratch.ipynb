{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a892bafd",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7726dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.5.1+cu121\n",
      "tensorflow version: could not be determined\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "from model import *\n",
    "from utils import *\n",
    "import importlib.metadata\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        print(f\"{p} version: {importlib.metadata.version(p)}\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        try:\n",
    "            mod = importlib.import_module(p)\n",
    "            print(f\"{p} version (from __version__): {mod.__version__}\")\n",
    "        except Exception:\n",
    "            print(f\"{p} version: could not be determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176892b",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c88f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"drop_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f69509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72a08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you rentingetic wasnم refres RexMeCHicular stren.\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Before trainin, we are just testing the model with a few tokens\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(f\"Output text: {token_ids_to_text(token_ids, tokenizer)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce61857",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a64b3",
   "metadata": {},
   "source": [
    "#### Dummy Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f929ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode(\"utf-8\")\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()\n",
    "# # First 100 characters\n",
    "# print(text_data[:99])\n",
    "\n",
    "# total_characters = len(text_data)\n",
    "# total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "# print(\"Characters:\", total_characters)\n",
    "# print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff27256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/validation ratio\n",
    "# train_ratio = 0.90\n",
    "# split_idx = int(train_ratio * len(text_data))\n",
    "# train_data = text_data[:split_idx]\n",
    "# val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# train_loader = create_dataloader_v1(\n",
    "#     train_data,\n",
    "#     batch_size=2,\n",
    "#     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     drop_last=True,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0,\n",
    "# )\n",
    "\n",
    "# val_loader = create_dataloader_v1(\n",
    "#     val_data,\n",
    "#     batch_size=2,\n",
    "#     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "#     drop_last=False,\n",
    "#     shuffle=False,\n",
    "#     num_workers=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbdcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check\n",
    "\n",
    "# if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "#     print(\"Not enough tokens for the training loader. \"\n",
    "#           \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "#           \"increase the `training_ratio`\")\n",
    "\n",
    "# if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "#     print(\"Not enough tokens for the validation loader. \"\n",
    "#           \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "#           \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965172eb",
   "metadata": {},
   "source": [
    "#### Actual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96305ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = \"roneneldan/TinyStories\"\n",
    "DATASET_DIR = \"./dataset/\"\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, cache_dir=DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [_[\"text\"] for _ in dataset[\"train\"]]\n",
    "val_data = [_[\"text\"] for _ in dataset[\"validation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a935c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v2(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v2(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9415a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5402bed",
   "metadata": {},
   "source": [
    "### Training the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09038603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8998eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():  # Only for Apple Silicon (Mac)\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae11760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"[Checkpoint Loaded] Epoch: {checkpoint['epoch']}, Step: {checkpoint['step']}\")\n",
    "        return checkpoint['epoch'] + 1, checkpoint['step'], checkpoint['tokens_seen'], checkpoint['best_val_loss']\n",
    "    else:\n",
    "        return 0, -1, 0, float('inf')  # Start fresh\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "    checkpoint_path=\"checkpoint.pt\",\n",
    "    best_model_path=\"best_model.pt\"\n",
    "):\n",
    "    # Load checkpoint if exists\n",
    "    start_epoch, global_step, tokens_seen, best_val_loss = load_checkpoint(model, optimizer, checkpoint_path, device)\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            for input_batch, target_batch in loop:\n",
    "                optimizer.zero_grad()\n",
    "                loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tokens_seen += input_batch.numel()\n",
    "                global_step += 1\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "                # Optional mid-training eval (rare for large models)\n",
    "                if global_step % eval_freq == 0:\n",
    "                    train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                    train_losses.append(train_loss)\n",
    "                    val_losses.append(val_loss)\n",
    "                    track_tokens_seen.append(tokens_seen)\n",
    "                    print(f\"[Step {global_step}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Epoch-end evaluation\n",
    "            train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "            print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"[Saved New Best Model @ Epoch {epoch+1}]\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'step': global_step,\n",
    "                'tokens_seen': tokens_seen,\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            # Show generated sample\n",
    "            generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[Training Interrupted] Saving checkpoint...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'step': global_step,\n",
    "            'tokens_seen': tokens_seen,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        print(\"[Checkpoint Saved Successfully]\")\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3563e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maazm\\AppData\\Local\\Temp\\ipykernel_11524\\3293950886.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint Loaded] Epoch: 0, Step: 62161\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# ========== Execution Start ==========\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize model, move to device\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# Run training (resumable + interrupt-safe)\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=1,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# ========== Execution End ==========\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8805af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maazm\\AppData\\Local\\Temp\\ipykernel_11524\\309443872.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"checkpoint.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"checkpoint.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward, even when progress seems invisible. The steps you take today echo in the foundations of tomorrow. Beneath the weight of struggle lies the quiet rise of transformation.\n"
     ]
    }
   ],
   "source": [
    "#Final Checkpoint ===> Loss 1.2\n",
    "generate_and_print_sample(model, tokenizer, device, start_context=\"Every effort moves you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc32f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me that cake. Ben and I are best friends. We are going to eat it together. I am so happy to have a friend like Ben. He is the best friend in the world. He is the best friend in the world.\n"
     ]
    }
   ],
   "source": [
    "#3rd Checkpoint ===> Loss 3.1\n",
    "generate_and_print_sample(model, tokenizer, device, start_context=\"Give me that cake.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry. They like to play with their toys. They see the toys. They see the birds. They see the toys and the toys. They see the birds. They see the birds and the birds. They see the ball.     \n"
     ]
    }
   ],
   "source": [
    "#2nd Checkpoint ===> Loss 4.5\n",
    "generate_and_print_sample(model, tokenizer, device, start_context=\"I'm sorry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de70a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maazm\\AppData\\Local\\Temp\\ipykernel_11524\\3293950886.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint Loaded] Epoch: 0, Step: 62161\n",
      "Training completed in 1374.20 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWNElEQVR4nO3dd3gUVdvA4d9u6iYhhfQACS1AgNCLIVIUJFQBRRFRQX1FqfqiqHwKUlRUEBFFUHwFC6KigogUAelEek8ILRBKCi29Z8/3x5JNFgIkkGQ3yXNf11zsnDkz8+yw2WfPzJkzGqWUQgghhBAWSWvuAIQQQghxa5KohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohagEzpw5g0aj4cCBA+YORQhRyiRRC2EhNBrNbafJkyebO0QhhBlYmzsAIYRBbGys8fXPP//MpEmTiIqKMpY5OTmZIywhhJlJi1oIC+Hj42OcXFxc0Gg0xnkvLy9mzZpFzZo1sbOzo0WLFqxZs+aW28rLy+O5556jUaNGxMTEAPDHH3/QqlUr7O3tqVu3LlOmTCE3N9e4jkaj4euvv2bAgAE4ODgQGBjIihUrjMuvXbvGkCFD8PT0RKfTERgYyMKFC28Zw6+//kpwcDA6nQ53d3e6detGWlqacfnXX39NUFAQ9vb2NGrUiC+++MJk/XPnzvH444/j6upK9erV6devH2fOnDEuHzZsGP3792fmzJn4+vri7u7OqFGjyMnJKfYxF6JCUEIIi7Nw4ULl4uJinJ81a5ZydnZWS5YsUceOHVOvv/66srGxUcePH1dKKRUdHa0AtX//fpWZmakGDBigWrZsqRISEpRSSm3ZskU5OzurRYsWqVOnTqm///5b1a5dW02ePNm4D0DVrFlT/fjjj+rEiRNq7NixysnJSV25ckUppdSoUaNUixYt1O7du1V0dLRat26dWrFiRZHxX7x4UVlbW6tZs2ap6OhodejQITV37lyVkpKilFLqhx9+UL6+vuq3335Tp0+fVr/99puqXr26WrRokVJKqezsbBUUFKSee+45dejQIRUREaGefPJJ1bBhQ5WVlaWUUmro0KHK2dlZvfTSSyoyMlL9+eefysHBQX311Vel+58hhJlJohbCAt2YqP38/NR7771nUqdt27Zq5MiRSqmCRL1161bVtWtXdf/996vExERj3a5du6r333/fZP3vv/9e+fr6GucB9fbbbxvnU1NTFaBWr16tlFKqb9++6tlnny1W/Hv37lWAOnPmTJHL69Wrp3788UeTsmnTpqmQkBBjbA0bNlR6vd64PCsrS+l0OrV27VqllCFRBwQEqNzcXGOdxx57TA0aNKhYMQpRUcg1aiEsXHJyMhcvXiQ0NNSkPDQ0lIMHD5qUDR48mJo1a/LPP/+g0+mM5QcPHmT79u289957xrK8vDwyMzNJT0/HwcEBgGbNmhmXOzo64uzsTEJCAgAjRozg0UcfZd++fXTv3p3+/fvToUOHImNu3rw5Xbt2JTg4mLCwMLp3787AgQNxc3MjLS2NU6dO8fzzz/PCCy8Y18nNzcXFxcUY78mTJ6lWrZrJdjMzMzl16pRxvkmTJlhZWRnnfX19OXz48G2OphAVjyRqISqRXr168cMPPxAeHs6DDz5oLE9NTWXKlCk88sgjN61jb29vfG1jY2OyTKPRoNfrAejZsydnz55l1apVrFu3jq5duzJq1Chmzpx50zatrKxYt24dO3bs4O+//+azzz7jrbfeYufOncYfBQsWLKB9+/Y3rZcfb+vWrVm8ePFN2/b09CxWvEJUFpKohbBwzs7O+Pn5sX37djp37mws3759O+3atTOpO2LECJo2bcrDDz/MX3/9ZazfqlUroqKiqF+//j3F4unpydChQxk6dCgdO3Zk/PjxRSZqMCTN0NBQQkNDmTRpEgEBASxbtoxx48bh5+fH6dOnGTJkSJHrtmrVip9//hkvLy+cnZ3vKWYhKjpJ1EJUAOPHj+edd96hXr16tGjRgoULF3LgwIEiW5xjxowhLy+PPn36sHr1au6//34mTZpEnz598Pf3Z+DAgWi1Wg4ePMiRI0d49913ixXDpEmTaN26NU2aNCErK4uVK1cSFBRUZN2dO3eyYcMGunfvjpeXFzt37uTSpUvG+lOmTGHs2LG4uLjQo0cPsrKy2LNnD9euXWPcuHEMGTKEGTNm0K9fP6ZOnUrNmjU5e/Ysv//+O6+//jo1a9a8+4MpRAUjiVqICmDs2LEkJSXx6quvkpCQQOPGjVmxYgWBgYFF1n/llVfQ6/X06tWLNWvWEBYWxsqVK5k6dSoffvghNjY2NGrUiP/85z/FjsHW1pYJEyZw5swZdDodHTt25KeffiqyrrOzM1u2bGH27NkkJycTEBDAxx9/TM+ePQH4z3/+g4ODAzNmzGD8+PE4OjoSHBzMK6+8AoCDgwNbtmzhjTfe4JFHHiElJYUaNWrQtWtXaWGLKkejlFLmDkIIIYQQRZMBT4QQQggLJolaCCGEsGCSqIUQQggLJolaCCGEsGCSqIUQQggLJolaCCGEsGBVPlFPnjwZjUZjMjVq1Mi4PDMzk1GjRuHu7o6TkxOPPvoo8fHxJtuIiYmhd+/eODg44OXlxfjx400eH1jRbdmyhb59++Ln54dGo2H58uUmy5VSTJo0CV9fX3Q6Hd26dePEiRMmda5evcqQIUNwdnbG1dWV559/ntTUVJM6hw4domPHjtjb21OrVi0++uijsn5rZeZOx2zYsGE3fe569OhhUqcqHbPp06fTtm1bqlWrhpeXF/379zd5FjeU3t/ipk2baNWqFXZ2dtSvX59FixaV9dsrE8U5Zl26dLnpc/bSSy+Z1KlKx2zevHk0a9YMZ2dnnJ2dCQkJYfXq1cblFvsZM/NDQczunXfeUU2aNFGxsbHG6dKlS8blL730kqpVq5basGGD2rNnj7rvvvtUhw4djMtzc3NV06ZNVbdu3dT+/fvVqlWrlIeHh5owYYI53k6ZWLVqlXrrrbfU77//rgC1bNkyk+UffPCBcnFxUcuXL1cHDx5UDz/8sKpTp47KyMgw1unRo4dq3ry5+vfff9XWrVtV/fr11eDBg43Lk5KSlLe3txoyZIg6cuSIWrJkidLpdOrLL78sr7dZqu50zIYOHap69Ohh8rm7evWqSZ2qdMzCwsLUwoUL1ZEjR9SBAwdUr169lL+/v0pNTTXWKY2/xdOnTysHBwc1btw4FRERoT777DNlZWWl1qxZU67vtzQU55h17txZvfDCCyafs6SkJOPyqnbMVqxYof766y91/PhxFRUVpf7v//5P2djYqCNHjiilLPczJon6nXdU8+bNi1yWmJiobGxs1NKlS41lkZGRClDh4eFKKcMXslarVXFxccY68+bNU87Ozsbn5lYmNyYdvV6vfHx81IwZM4xliYmJys7OTi1ZskQppVRERIQC1O7du411Vq9erTQajbpw4YJSSqkvvvhCubm5mRyzN954QzVs2LCM31HZu1Wi7tev3y3XqerHLCEhQQFq8+bNSqnS+1t8/fXXVZMmTUz2NWjQIBUWFlbWb6nM3XjMlDIk6pdffvmW61T1Y6aUUm5uburrr7+26M9YlT/1DXDixAn8/PyoW7cuQ4YMISYmBoC9e/eSk5NDt27djHUbNWqEv78/4eHhAISHhxMcHIy3t7exTlhYGMnJyRw9erR834gZREdHExcXZ3KMXFxcaN++vckxcnV1pU2bNsY63bp1Q6vVsnPnTmOdTp06YWtra6wTFhZGVFQU165dK6d3U742bdqEl5cXDRs2ZMSIEVy5csW4rKofs6SkJACqV68OlN7fYnh4uMk28uvkb6Miu/GY5Vu8eDEeHh40bdqUCRMmkJ6eblxWlY9ZXl4eP/30E2lpaYSEhFj0Z6zKj/Xdvn17Fi1aRMOGDYmNjWXKlCl07NiRI0eOEBcXh62tLa6uribreHt7ExcXB0BcXJzJf1r+8vxllV3+eyzqGBQ+Rl5eXibLra2tqV69ukmdOnXq3LSN/GVubm5lEr+59OjRg0ceeYQ6depw6tQp/u///o+ePXsSHh6OlZVVlT5mer2eV155hdDQUJo2bQpQan+Lt6qTnJxMRkaGyTO8K5KijhnAk08+SUBAAH5+fhw6dIg33niDqKgofv/9d6BqHrPDhw8TEhJCZmYmTk5OLFu2jMaNG3PgwAGL/YxV+USd/5AAgGbNmtG+fXsCAgL45ZdfKtwHUFQcTzzxhPF1cHAwzZo1o169emzatImuXbuaMTLzGzVqFEeOHGHbtm3mDqXCuNUxGz58uPF1cHAwvr6+dO3alVOnTlGvXr3yDtMiNGzYkAMHDpCUlMSvv/7K0KFD2bx5s7nDui059X0DV1dXGjRowMmTJ/Hx8SE7O5vExESTOvHx8fj4+ADg4+NzU6/A/Pn8OpVZ/nss6hgUPkYJCQkmy3Nzc7l69aocx+vq1q2Lh4cHJ0+eBKruMRs9ejQrV65k48aNJo+yLK2/xVvVcXZ2rrA/zG91zIrSvn17AJPPWVU7Zra2ttSvX5/WrVszffp0mjdvzqeffmrRnzFJ1DdITU3l1KlT+Pr60rp1a2xsbNiwYYNxeVRUFDExMYSEhAAQEhLC4cOHTb5U161bh7OzM40bNy73+MtbnTp18PHxMTlGycnJ7Ny50+QYJSYmsnfvXmOdf/75B71eb/ziCAkJYcuWLeTk5BjrrFu3joYNG1bYU7glcf78ea5cuYKvry9Q9Y6ZUorRo0ezbNky/vnnn5tO6ZfW32JISIjJNvLr5G+jIrnTMSvKgQMHAEw+Z1XpmBVFr9eTlZVl2Z+xu+6GVkm8+uqratOmTSo6Olpt375ddevWTXl4eKiEhASllKG7vr+/v/rnn3/Unj17VEhIiAoJCTGun99dv3v37urAgQNqzZo1ytPTs1LdnpWSkqL279+v9u/frwA1a9YstX//fnX27FmllOH2LFdXV/XHH3+oQ4cOqX79+hV5e1bLli3Vzp071bZt21RgYKDJrUaJiYnK29tbPf300+rIkSPqp59+Ug4ODhXyViOlbn/MUlJS1GuvvabCw8NVdHS0Wr9+vWrVqpUKDAxUmZmZxm1UpWM2YsQI5eLiojZt2mRyK1F6erqxTmn8LebfOjN+/HgVGRmp5s6dW2FvNbrTMTt58qSaOnWq2rNnj4qOjlZ//PGHqlu3rurUqZNxG1XtmL355ptq8+bNKjo6Wh06dEi9+eabSqPRqL///lspZbmfsSqfqAcNGqR8fX2Vra2tqlGjhho0aJA6efKkcXlGRoYaOXKkcnNzUw4ODmrAgAEqNjbWZBtnzpxRPXv2VDqdTnl4eKhXX31V5eTklPdbKTMbN25UwE3T0KFDlVKGW7QmTpyovL29lZ2dneratauKiooy2caVK1fU4MGDlZOTk3J2dlbPPvusSklJMalz8OBBdf/99ys7OztVo0YN9cEHH5TXWyx1tztm6enpqnv37srT01PZ2NiogIAA9cILL5jc8qFU1TpmRR0rQC1cuNBYp7T+Fjdu3KhatGihbG1tVd26dU32UZHc6ZjFxMSoTp06qerVqys7OztVv359NX78eJP7qJWqWsfsueeeUwEBAcrW1lZ5enqqrl27GpO0Upb7GdMopdTdt8eFEEIIUZbkGrUQQghhwSRRCyGEEBZMErUQQghhwSRRCyGEEBZMErUQQghhwSRRCyGEEBZMEnUJZGVlMXnyZLKysswdSoUhx6zk5JiVnByzkpNjVnLmOmZyH3UJJCcn4+LiQlJSEs7OzuYOp0KQY1ZycsxKTo5ZyckxKzlzHTNpUQshhBAWTBK1EEIIYcEq/fOoc3Nz2b9/P97e3mi19/a7JCUlBYALFy6QnJxcGuFVenLMSk6OWcnJMSs5OWYlV5rHTK/XEx8fT8uWLbG2vn0qrvTXqHfv3k27du3MHYYQQghxk127dtG2bdvb1qn0LWpvb2/AcDDyn8EqhBBCmFNsbCzt2rUz5qjbqfSJOv90t6+vLzVr1jRzNEIIIUSB4lySlc5kQgghhAUza6LesmULffv2xc/PD41Gw/Lly02WK6WYNGkSvr6+6HQ6unXrxokTJ8wTrBBCCGEGZk3UaWlpNG/enLlz5xa5/KOPPmLOnDnMnz+fnTt34ujoSFhYGJmZmeUcqRBCCGEeZr1G3bNnT3r27FnkMqUUs2fP5u2336Zfv34AfPfdd3h7e7N8+XKeeOKJ8gxVCFFF5OXlkZOTY+4wRAVnY2ODlZVVqWzLYjuTRUdHExcXR7du3YxlLi4utG/fnvDwcLMk6nNX09ly4hJD2geU+76FEGVLKUVcXByJiYnmDkVUEq6urvj4+KDRaO5pOxabqOPi4gBu6rru7e1tXFaUrKwskwHT829Qv1fxyZn0+GQjr3vOJ9pmIHVaDS2V7QohLEN+kvby8sLBweGev1xF1aWUIj09nYSEBIB7vjXYYhP13Zo+fTpTpkwp9e16O9szsfFOnlAryYlcS56vP1a+D5T6foQQ5S8vL8+YpN3d3c0djqgEdDodAAkJCXh5ed3TaXCLvT3Lx8cHgPj4eJPy+Ph447KiTJgwgaSkJOMUERFRajE92PsN1qWEYqPJIW9TP7h2oNS2LYQwn/xr0g4ODmaORFQm+Z+ne+3zYLGJuk6dOvj4+LBhwwZjWXJyMjt37iQkJOSW69nZ2eHs7GycqlWrVmoxeTk7Etfka3amNsVWpaD/pwekni617QshzEtOd4vSVFqfJ7Mm6tTUVA4cOMCBAwcAQweyAwcOEBMTg0aj4ZVXXuHdd99lxYoVHD58mGeeeQY/Pz/69+9vtpgHhzRgZuaHRGbURpsVD/90h4z4O68ohBBC3AWzJuo9e/bQsmVLWrZsCcC4ceNo2bIlkyZNAuD1119nzJgxDB8+nLZt25KamsqaNWuwt7c3W8zWVlre7BfCM9FTOZftDamnYFMvyJGnzwghKofatWsze/bsYtfftGkTGo2mzHvML1q0CFdX1zLdhyUya6Lu0qULSqmbpkWLFgGG0wZTp04lLi6OzMxM1q9fT4MGDcwZMgCtA9x4oEUznj49lUS9K1zbB1segbysO64rhBClRaPR3HaaPHnyXW139+7dDB8+vNj1O3ToQGxsLC4uLne1P3F7FnuN2tK90aMR16xq89SpyWRrHCF+A4Q/A0pv7tCEEFVEbGyscZo9ezbOzs4mZa+99pqxrlKK3NzcYm3X09OzRB3rbG1tS+V+YVE0SdR3yd3Jjtd7NORIRn1GxbyF0thAzC+w92Wo3I/4FkJYCB8fH+Pk4uKCRqMxzh87doxq1aqxevVqWrdujZ2dHdu2bePUqVP069cPb29vnJycaNu2LevXrzfZ7o2nvjUaDV9//TUDBgzAwcGBwMBAVqxYYVx+46nv/FPUa9euJSgoCCcnJ3r06EFsbKxxndzcXMaOHYurqyvu7u688cYbDB06tMR9kObNm0e9evWwtbWlYcOGfP/998ZlSikmT56Mv78/dnZ2+Pn5MXbsWOPyL774gsDAQOzt7fH29mbgwIEl2nd5kUR9D55o60/zmi6su9aMb5kKaOD45xAx3dyhCSHukVKK9Oxcs0yqFH/sv/nmm3zwwQdERkbSrFkzUlNT6dWrFxs2bGD//v306NGDvn37EhMTc9vtTJkyhccff5xDhw7Rq1cvhgwZwtWrV29ZPz09nZkzZ/L999+zZcsWYmJiTFr4H374IYsXL2bhwoVs376d5OTkmx7MdCfLli3j5Zdf5tVXX+XIkSO8+OKLPPvss2zcuBGA3377jU8++YQvv/ySEydOsHz5coKDgwFDH6mxY8cydepUoqKiWLNmDZ06dSrR/stLpRvwpDxZaTVM69+UfnO3M/lgMJ36vkfdC++BWytzhyaEuEcZOXk0nrTWLPuOmBqGg23pfD1PnTqVhx56yDhfvXp1mjdvbpyfNm0ay5YtY8WKFYwePfqW2xk2bBiDBw8G4P3332fOnDns2rWLHj16FFk/JyeH+fPnU69ePQBGjx7N1KlTjcs/++wzJkyYwIABAwD4/PPPWbVqVYne28yZMxk2bBgjR44EDB2S//33X2bOnMkDDzxATEwMPj4+dOvWDRsbG/z9/WnXrh0AMTExODo60qdPH6pVq0ZAQICxY7OlkRb1PWpW05Uh7f0BGL6zA9k9IsCv6A+uEEKUtzZt2pjMp6am8tprrxEUFISrqytOTk5ERkbesUXdrFkz42tHR0ecnZ2NQ2QWxcHBwZikwTCMZn79pKQk4uPjjUkTwMrKitatW5fovUVGRhIaGmpSFhoaSmRkJACPPfYYGRkZ1K1blxdeeIFly5YZr9M/9NBDBAQEULduXZ5++mkWL15Menp6ifZfXqRFXQrGd2/E6sNxnExI5Zv9ObzU+fqC5BOQlQCeobddXwhheXQ2VkRMDTPbvkuLo6Ojyfxrr73GunXrmDlzJvXr10en0zFw4ECys7Nvux0bGxuTeY1Gg15/686zRdUvzVP6xVGrVi2ioqJYv34969atY+TIkcyYMYPNmzdTrVo19u3bx6ZNm/j777+ZNGkSkydPZvfu3RZ3C5i0qEuBi4MNb/ZsBMCn609wMTEDkiJhXShs6g2Jh80coRCipDQaDQ621maZyrL39Pbt2xk2bBgDBgwgODgYHx8fzpw5U2b7K4qLiwve3t7s3r3bWJaXl8e+fftKtJ2goCC2b99uUrZ9+3YaN25snNfpdPTt25c5c+awadMmwsPDOXzY8J1sbW1Nt27d+Oijjzh06BBnzpzhn3/+uYd3VjakRV1KHm1Vk593n2PP2WtMWxnBvCcag3NDyMsAe+87b0AIIcpBYGAgv//+O3379kWj0TBx4sTbtozLypgxY5g+fTr169enUaNGfPbZZ1y7dq1EP1LGjx/P448/TsuWLenWrRt//vknv//+u7EX+6JFi8jLy6N9+/Y4ODjwww8/oNPpCAgIYOXKlZw+fZpOnTrh5ubGqlWr0Ov1NGzYsKze8l2TFnUp0Wo1TO3XFK0GVh+JY/PpVOj8J3TdCPZe5g5PCCEAmDVrFm5ubnTo0IG+ffsSFhZGq1bl3wH2jTfeYPDgwTzzzDOEhITg5OREWFhYiUae7N+/P59++ikzZ86kSZMmfPnllyxcuJAuXboAhudBL1iwgNDQUJo1a8b69ev5888/cXd3x9XVld9//50HH3yQoKAg5s+fz5IlS2jSpEkZveO7p1HlfdGgnJ0/f55atWpx7tw5atasWeb7m/LnURZuP0MdD0fWvNIRO+tC15rOLQOfh8DGqczjEEIUX2ZmJtHR0dSpU8esQxRXZXq9nqCgIB5//HGmTZtm7nBKxe0+VyXJTdKiLmX/fagBntXsiL6cxlebCz1ZK+oz2PqIYcq7facNIYSo7M6ePcuCBQs4fvw4hw8fZsSIEURHR/Pkk0+aOzSLI4m6lDnb2/B27yAAPt94knNXr3f3d28PVg4Qtw7+HSZDjQohqjStVsuiRYto27YtoaGhHD58mPXr1xMUFGTu0CyOJOoy8HBzP0LqupOVq2fKn0cNhR7toOPvoLGGs0tg3zgZalQIUWXVqlWL7du3k5SURHJyMjt27LDYkcHMTRJ1GdBoNEzt1wRrrYb1kQmsj7j+vGq/MLhvkeF11KcQ8aHZYhRCCFExSKIuI4He1Xi+Yx0AJv95lIzsPMOCOkOg1SzD64MT4NRCM0UohBCiIpBEXYbGPhiIr4s9569lMG/TyYIFjf4LQa8bXu96Ac7/aZ4AhRBCWDxJ1GXI0c6aSX0MI+TM33ya6MtpBQtbfAB1hoLKg+2Pw6Xtt9iKEEKIqkwSdRnr0dSHjoEeZOfpeWfF0YKxbjUaaL8A/HpDXiZs6gOJR8wbrBBCCIsjibqMGTqWNcXWSsuW45dYcySuYKHWBu7/BTxCICcRNoZB2lmzxSqEEMLySKIuB3U8HHmxc10Apq6MIC0rt2ChtQN0XgnOQZBxEWLXmSlKIURV1aVLF1555RXjfO3atZk9e/Zt19FoNCxfvvye911a27mdyZMn06JFizLdR1mSRF1ORnapT003HbFJmcz554TpQrvq8MBa6LAY6v/HPAEKISqcvn370qNHjyKXbd26FY1Gw6FDh0q83d27dzN8+PB7Dc/ErZJlbGwsPXv2LNV9VTaSqMuJztaKyX0Ng73/b2s0J+JTTCs41oLahYbOy0kBfU45RiiEqGief/551q1bx/nz529atnDhQtq0aUOzZs1KvF1PT08cHBxKI8Q78vHxwc7Orlz2VVFJoi5H3Rp70y3Ii1y9YtIfR2/9EPXMBFjfBf59ToYaFULcUp8+ffD09GTRokUm5ampqSxdupTnn3+eK1euMHjwYGrUqIGDgwPBwcEsWbLkttu98dT3iRMn6NSpE/b29jRu3Jh1626+RPfGG2/QoEEDHBwcqFu3LhMnTiQnx9DYWLRoEVOmTOHgwYNoNBo0Go0x5htPfR8+fJgHH3wQnU6Hu7s7w4cPJzU11bh82LBh9O/fn5kzZ+Lr64u7uzujRo0y7qs49Ho9U6dOpWbNmtjZ2dGiRQvWrFljXJ6dnc3o0aPx9fXF3t6egIAApk+fDoBSismTJ+Pv74+dnR1+fn6MHTu22Pu+GxadqPPy8pg4cSJ16tRBp9NRr149pk2bdusEVwG807cJdtZawk9fYcXBi0VXunYQEg9C7FpIP1e+AQohTOWmlXzSF+qHos+9Xp5RvO2WgLW1Nc888wyLFi0y+V5cunQpeXl5DB48mMzMTFq3bs1ff/3FkSNHGD58OE8//TS7du0q1j70ej2PPPIItra27Ny5k/nz5/PGG2/cVK9atWosWrSIiIgIPv30UxYsWMAnn3wCwKBBg3j11Vdp0qQJsbGxxMbGMmjQoJu2kZaWRlhYGG5ubuzevZulS5eyfv16Ro8ebVJv48aNnDp1io0bN/Ltt9+yaNGim36s3M6nn37Kxx9/zMyZMzl06BBhYWE8/PDDnDhhuCw5Z84cVqxYwS+//EJUVBSLFy+mdu3aAPz222988sknfPnll5w4cYLly5cTHBxc7H3fFWXB3nvvPeXu7q5WrlypoqOj1dKlS5WTk5P69NNPi72Nc+fOKUCdO3euDCMtmTnrj6uAN1aqtu+uU8kZ2UVXOvuLUknHyzcwIaqojIwMFRERoTIyMm5euJiST2d/KVj/7C+GsnWdTbf7q0fR65ZQZGSkAtTGjRuNZR07dlRPPfXULdfp3bu3evXVV43znTt3Vi+//LJxPiAgQH3yySdKKaXWrl2rrK2t1YULF4zLV69erQC1bNmyW+5jxowZqnXr1sb5d955RzVv3vymeoW389VXXyk3NzeVmppqXP7XX38prVar4uLilFJKDR06VAUEBKjc3Fxjnccee0wNGjTolrHcuG8/Pz/13nvvmdRp27atGjlypFJKqTFjxqgHH3xQ6fX6m7b18ccfqwYNGqjs7Ft8dxdyu89VSXKTRbeod+zYQb9+/ejduze1a9dm4MCBdO/evdi/BC3VC53qUtvdgYSULD5Zd6LoSv6PgXNgwXx2YrnEJoSoWBo1akSHDh345ptvADh58iRbt27l+eefBwxnJqdNm0ZwcDDVq1fHycmJtWvXEhMTU6ztR0ZGUqtWLfz8/IxlISEhN9X7+eefCQ0NxcfHBycnJ95+++1i76Pwvpo3b46jo6OxLDQ0FL1eT1RUlLGsSZMmWFlZGed9fX1JSEgo1j6Sk5O5ePEioaGhJuWhoaFERkYChtPrBw4coGHDhowdO5a///7bWO+xxx4jIyODunXr8sILL7Bs2TJyc3MpSxadqDt06MCGDRs4fvw4AAcPHmTbtm0VvoegvY0VU/o1BeDb8DNExibffoWLa+CP2nDhr7IPTghh6vHUkk81BxSsX3OAoazLatPt9jtT9Lp34fnnn+e3334jJSWFhQsXUq9ePTp37gzAjBkz+PTTT3njjTfYuHEjBw4cICwsjOzs7Ls8IDcLDw9nyJAh9OrVi5UrV7J//37eeuutUt1HYTY2NibzGo0Gvb70+vO0atWK6Ohopk2bRkZGBo8//jgDBw4EDE/9ioqK4osvvkCn0zFy5Eg6depUomvkJWXRifrNN9/kiSeeoFGjRtjY2NCyZUteeeUVhgwZcst1srKySE5ONk4pKSm3rGtOnRt40rOpD3l6xcTlR9Drb3PdPWYp5CTBtsfg8r/lF6QQAqwdSz5prQvW11pfL9cVb7t34fHHH0er1fLjjz/y3Xff8dxzz6HRaADYvn07/fr146mnnqJ58+bUrVvX2PgpjqCgIM6dO0dsbKyx7N9/Tb+HduzYQUBAAG+99RZt2rQhMDCQs2dNB2+ytbUlLy/vjvs6ePAgaWkF1+q3b9+OVqulYcOGxY75dpydnfHz82P7dtNhm7dv307jxo1N6g0aNIgFCxbw888/89tvv3H16lUAdDodffv2Zc6cOWzatInw8HAOHz5cKvEVxaIT9S+//MLixYv58ccf2bdvH99++y0zZ87k22+/veU606dPx8XFxTgVPvCWZmKfxjjYWrHn7DV+23fz7RVG7eaDb0/Iy4BNvSEpsvyCFEJYPCcnJwYNGsSECROIjY1l2LBhxmWBgYGsW7eOHTt2EBkZyYsvvkh8fHyxt92tWzcaNGjA0KFDOXjwIFu3buWtt94yqRMYGEhMTAw//fQTp06dYs6cOSxbtsykTu3atYmOjubAgQNcvnyZrKysm/Y1ZMgQ7O3tGTp0KEeOHGHjxo2MGTOGp59+Gm9v75IdlNsYP348H374IT///DNRUVG8+eabHDhwgJdffhmAWbNmsWTJEo4dO8bx48dZunQpPj4+uLq6smjRIv73v/9x5MgRTp8+zQ8//IBOpyMgIKDU4ruRRSfq8ePHG1vVwcHBPP300/z3v/81dpMvyoQJE0hKSjJOERER5Rhxyfi56hjb1XAd+oPVx0hKv8WpE60NdFwK7u0h+yps7A5p0htcCFHg+eef59q1a4SFhZlcT3777bdp1aoVYWFhdOnSBR8fH/r371/s7Wq1WpYtW0ZGRgbt2rXjP//5D++9955JnYcffpj//ve/jB49mhYtWrBjxw4mTpxoUufRRx+lR48ePPDAA3h6ehZ5i5iDgwNr167l6tWrtG3bloEDB9K1a1c+//zzkh2MOxg7dizjxo3j1VdfJTg4mDVr1rBixQoCAw3fx9WqVeOjjz6iTZs2tG3bljNnzrBq1Sq0Wi2urq4sWLCA0NBQmjVrxvr16/nzzz9xd3cv1RgL0yhlufc6ubu78+677zJixAhj2fTp01m4cGGxT92cP3+eWrVqce7cOWrWrFlWod617Fw9veZs5WRCKk/fF8C0/k1vXTnrCqy7H5KPgUtj6LbVMKqZEOKeZGZmEh0dTZ06dbC3tzd3OKKSuN3nqiS5yaJb1H379uW9997jr7/+4syZMyxbtoxZs2YxYMCAO69cQdhaa5l2vWPZDzvPcvh80q0r27kbhhrV1YCkCNjcB3LTyylSIYQQ5mDRifqzzz5j4MCBjBw5kqCgIF577TVefPFFpk2bZu7QSlVIPXf6tfBDKXj7jzt0LHP0NyRrG1e4HA7bHpehRoUQohKz6ERdrVo1Zs+ezdmzZ8nIyODUqVO8++672Nramju0UvdWryCc7Kw5eC6Rn3bf4fqzaxPoshKs7OHiX7BrOFjuFQwhhBD3wKITdVXi5WzPfx9qAMBHa49xNe0O9x96hkLoL6CxgtOL4OCEsg9SCCFEuZNEbUGGhgTQyKcaiek5fLTm2J1XqNkX2i0wvI74EM7/WbYBCiGEKHeSqC2ItZWWd6/3+v5p9zn2xVy780r1noXm0yFwJPj1KuMIhajcSnN0KyFK6/Nkfecqojy1qV2dga1r8uve80xcfoQVo+/HSqu5/UqNrz/JRnOHekKIItna2qLVarl48SKenp7Y2toaR/YSoqSUUmRnZ3Pp0iW0Wu0996uSRG2B3uzZiL+PxnH0YjI//HuWoR1q336Fwl8o+hzYMxrqPgce7cs0TiEqC61WS506dYiNjeXixVs8flaIEnJwcMDf3x+t9t5OXkuitkAeTnaM79GIicuPMPPvKHoF++JZza54Kx95D05+BedXwMOnwNqhbIMVopKwtbXF39+f3NzcO45JLcSdWFlZYW1tXSpnZiRRW6gn2/mzdM85Dp1PYvqqSGYNalG8FYNeg4TN0Ph1SdJClJBGo8HGxuampzMJYU7SmcxCWWk1TOvXFI0Gft9/gZ2nrxRvRRsn6PoP+BV6FGj6BbnPWgghKihJ1BaseS1XnmjrD8CkP46Sk1fMHoSFT7WkRsOqZoZBUfJuflqNEEIIyyaJ2sK9HtYQNwcbouJT+HbHmZJvIGEr5CTCqa9hfWdD61oIIUSFIYnawrk52vJmz0YAfLLuOHFJmSXbQN1noMtqsHWDKzthTWtD8hZCCFEhSKKuAB5rXYtW/q6kZefx7l938Xxt3+7QYw+4NoPMeNjwIByfK9ethRCiApBEXQFotRqm9W+KVgMrD8Wy/eTlkm/EqS503wH+g0DlGu613vk85JWwhS6EEKJcSaKuIJr4ufBMSG0AJv5xhKzcu7jP09oRQpdAyxmg0cLphbCuE6Td4WldQgghzEYSdQUyrnsDPJzsOH0pja+3Rt/dRjQaw73WD6wF2+pwdTesbQMJW0o3WCGEEKVCEnUF4mxvw1u9DR3LPvvnBBcSM+5+Yz7drl+3bg6ZCbChK0R9JtethRDCwkiirmD6t6hBuzrVyczRM/XPo/e2Mac6huvWAYMN162v7i2dIIUQQpQaSdQVjEZjGLHMSqth7dF4NkYl3NsGrR2gw2K471toN1+ewCWEEBZGEnUF1NCnGs+F1gZg8oqjZObc4wMENBrD/dZW9oZ5pYfwYRC/6d62K4QQ4p5Joq6gXu7WAG9nO85eSWf+5lOlu/ET8yD6W9jcF7Kulu62hRBClIgk6grKyc6aiX0aA/DFplOcvZJWehuv+xzUfgrafgF21Utvu0IIIUpMEnUF1jvYl/vre5Cdq2fyiqOo0uqxba2DkO+gztMFZdcOQOqZ0tm+EEKIYpNEXYFpNBqm9GuCjZWGjVGXWBcRX5obL3idEW84Db62DcRtKL19CCGEuCNJ1BVcPU8nhneqC8CUPyPIyL7HjmVFUTlg7w1ZV2Bjd4icJfdbCyFEObH4RH3hwgWeeuop3N3d0el0BAcHs2fPHnOHZVFGPxBIDVcdFxIz+HzjidLfgUNN6LYV6jxj6BG+/1XYMQRy00t/X0IIIUxYdKK+du0aoaGh2NjYsHr1aiIiIvj4449xc3Mzd2gWRWdrxaS+ho5lX205zalLqaW/E2sd3LcIWs8BjRWcXQJ/d4DUuxzKVAghRLFYdKL+8MMPqVWrFgsXLqRdu3bUqVOH7t27U69ePXOHZnG6N/bmgYae5OQp3vmjFDuWFabRQMMx8OAGsPOExIOwpg3ErS/9fQkhhAAsPFGvWLGCNm3a8Nhjj+Hl5UXLli1ZsGDBbdfJysoiOTnZOKWkpJRTtOal0WiY/HATbK21bDt5mb8Ox5bdzrw7Q4+9UL0tZF+FjWEQOVOuWwshRBmw6ER9+vRp5s2bR2BgIGvXrmXEiBGMHTuWb7/99pbrTJ8+HRcXF+PUuHHjcozYvALcHRnZxXC2YdrKCFKzcstuZ4614KEtUHfY9evW42HHk5BbivdzCyGEQKPK5Bxp6bC1taVNmzbs2LHDWDZ27Fh2795NeHh4ketkZWWRlZVlnL9w4QKNGzfm3Llz1KxZs8xjNrfMnDzCZm/h7JV0ng2tzTt9m5TtDpUyjGS292XDgz1cmxlOjdt7lO1+hRCiAjt//jy1atUqVm6y6Ba1r6/vTS3ioKAgYmJibrmOnZ0dzs7OxqlatWplHaZFsbexYvLDhuS8cPsZ5m48WbY71GigwUjo+g/Ye4GDv4xmJoQQpciiE3VoaChRUVEmZcePHycgIMBMEVUMDzT0YtxDDQCYsTaKWX9HlU3nssK8OhquW3f4HjTXP1Z52XLdWggh7pFFJ+r//ve//Pvvv7z//vucPHmSH3/8ka+++opRo0aZOzSLN7ZrIG/0aATAnH9O8sGaY2WfrB1qgq2r4bVSsOsF2D4IcsrgdjEhhKgi7ipRnzt3jvPnzxvnd+3axSuvvMJXX31VaoEBtG3blmXLlrFkyRKaNm3KtGnTmD17NkOGDCnV/VRWI7rUY9L1B3d8ufk0U/6MKPtknS/pqOFe63O/GcYJF0IIcVes72alJ598kuHDh/P0008TFxfHQw89RJMmTVi8eDFxcXFMmjSp1ALs06cPffr0KbXtVTXP3V8HW2stby8/wqIdZ8jO0/Nuv6ZotZo7r3wvXJtC142GhO11f9nuSwghKrG7alEfOXKEdu3aAfDLL7/QtGlTduzYweLFi1m0aFFpxidKwVP3BfDRwGZoNPDjzhhe/+0QefpyaFl7hkL94QXzyVEQMUOuWwshRAncVYs6JycHOzs7ANavX8/DDz8MQKNGjYiNLcOBNsRde7xNLeystYz75SC/7j1Pdq6eWY83x9qqnLop5GXClv6QfAyu7IT7FoJN1eqRL4QQd+OuvqWbNGnC/Pnz2bp1K+vWraNHjx4AXLx4EXd391INUJSefi1q8NngllhrNaw4eJExS/aTnasvn51b2UOj/4LWxnDd+u/7ILkMHiAihBCVzF0l6g8//JAvv/ySLl26MHjwYJo3bw4YhvzMPyUuLFOvYF/mP9UaWystq4/EMeKHvWTmlMGjMYtSfzh03Qw6X0iKgLVt4cJf5bNvIYSooO56ZLK8vDySk5NNnmR15swZHBwc8PLyKrUA71VJRn+pSjZFJfDi93vJytXTMdCDr55ug87Wqnx2nhELWwfC5R2ABppNhSb/V3D/tRBCVHJlPjJZRkYGWVlZxiR99uxZZs+eTVRUlEUlaXFrXRp6sXBYW3Q2Vmw9cZnnFu0mrSzHBi9M52voEV7/JUDBoYmw4QG5jUsIIYpwV4m6X79+fPfddwAkJibSvn17Pv74Y/r378+8efNKNUBRdjrU9+C759vhZGdN+OkrDP1mFymZOeWzcytbaDcP2i0wXL9O2AJrWsOulyDzUvnEIIQQFcBdJep9+/bRsWNHAH799Ve8vb05e/Ys3333HXPmzCnVAEXZalu7Ot8/345q9tbsOXuNp/63i6T0ckrWAPX/A32Ogf8gw1O4Tn4JfwbCiS/LLwYhhLBgd5Wo09PTjQ+7+Pvvv3nkkUfQarXcd999nD17tlQDFGWvpb8bS164D1cHGw6eS+TJr//lalp2+QXgGAD3/wTdtoBbS8hJguxr5bd/IYSwYHeVqOvXr8/y5cs5d+4ca9eupXv37gAkJCTg7OxcqgGK8tG0hgs/Db8PDydbjl5MZvBX/3IpJevOK5Ymr44QthtCvjfcypXv6l5IPl6+sQghhIW4q0Q9adIkXnvtNWrXrk27du0ICQkBDK3rli1blmqAovw08nHmp+EheFWzIyo+hUFfhROXlFm+QWitoM5TYGUYUAd9LoQPhVVN4fwf5RuLEEJYgLtK1AMHDiQmJoY9e/awdu1aY3nXrl355JNPSi04Uf7qeznxy4sh+LnYc/pSGoO+CudCYob5AspONJwat3EGr07mi0MIIczkrm9c9fHxoWXLlly8eNH4JK127drRqFGjUgtOmEdtD0d+fjGEWtV1nL2SzuPzw4m5km6eYOw9oMtf0PMg2F6/Z18p2DMGEraaJyYhhChHd5Wo9Xo9U6dOxcXFhYCAAAICAnB1dWXatGno9eU0JKUoU7WqO/DLiyHU8XDkQmIGj38ZzulLZnyutEONgtfnl8Pxz2F9J9j2BKTFmC0sIYQoa3eVqN966y0+//xzPvjgA/bv38/+/ft5//33+eyzz5g4cWJpxyjMxNdFx8/D7yPQy4m45Ewe//JfjsenmDusQk/l0kDMz7CyERyaDLlmavULIUQZuqshRP38/Jg/f77xqVn5/vjjD0aOHMmFCxdKLcB7JUOI3rsrqVk89b9dRMYmU93Rlh+eb09jPwvo3X/tAOx92TBYCoBDLWjxEQQMAk0ZP29bCCHuQZkPIXr16tUir0U3atSIq1ev3s0mhQVzd7JjyQvtCa7hwtW0bAYv+JdD5xPNHRa4tYCum+D+pYYOZ+nnYMdgwynxq/vMHJwQQpSOu0rUzZs35/PPP7+p/PPPP6dZs2b3HJSwPK4Otix+oT2t/F1JyshhyIKd7D1rAYOSaDTgPxB6R0KzaWDlAJe2wZo2sPMFyIg3d4RCCHFP7urU9+bNm+nduzf+/v7Ge6jDw8M5d+4cq1atMg4vagnk1HfpSs3K5blFu9kVfRUHWyu+GdaW++pa0DPI08/DgTfhzGLDvI0zNH0HgsaZNy4hhCikzE99d+7cmePHjzNgwAASExNJTEzkkUce4ejRo3z//fd3FbSoGJzsrPn22XbcX9+D9Ow8hi3cxbYTl80dVgGHmtDhB3hoO1RvAznJkHTE3FEJIcRdu+vnURfl4MGDtGrViry8vNLa5D2TFnXZyMzJY8QPe9kYdQlbay1fPtWaBxpZ2CNOlR6ivwPfHqDzMZSlnoG8DHAJMmtoQoiqrcxb1ELY21gx/+nWdG/sTXaunuHf72Ht0Thzh2VKo4W6wwqSNBh6ia9qBie/NltYQghREpKoxV2zs7Zi7pBW9G7mS06eYuTiffx58KK5w7q1vELjlnuGmi8OIYQogQqVqD/44AM0Gg2vvPKKuUMR19lYafl0UAseaVmDPL3i5Z/28/u+8+YOq2hW9tD5D+h91PTUd8RHEL/JbGEJIcTtWJek8iOPPHLb5YmJifcSy23t3r2bL7/8Um7/skDWVlpmPNYcW2stP+0+x6tLD5Kdq+eJdv7mDq1ozg0KXl87CAcnGK5n1xoILWeAU22zhSaEEDcqUYvaxcXltlNAQADPPPNMqQeZmprKkCFDWLBgAW5ubqW+fXHvrLQa3h8QzDMhASgFb/5+mO/Cz5g7rDtzqAn1XzJczz73q2E40oMTITfN3JEJIQRQwhb1woULyyqO2xo1ahS9e/emW7duvPvuu7etm5WVRVZWlnE+JcUCxqauIrRaDVMeboKtlZavt0Uz6Y+jZOfq+U/HuuYO7dbs3KHtXAh8ydDRLH4jHH0XTi+EFh9C7SdlOFIhhFlZ/DXqn376iX379jF9+vRi1Z8+fbpJK79x48ZlHKEoTKPR8FbvIEY9UA+Ad/+KZO7Gk2aOqhhcg+HBDdDxN3CsDRkXIPwpWBcKV3abOzohRBVm0Yn63LlzvPzyyyxevBh7e/tirTNhwgSSkpKMU0RERBlHKW6k0WgYH9aIcQ8ZrgXPWBvFrL+jKMVb9suGRgO1HoE+kdD8fbB2hMvhsLYd/PssZMSaO0IhRBVUqgOelLbly5czYMAArKysjGV5eXloNBq0Wi1ZWVkmy4oiA56Y1/zNp/hg9TEAXuxclzd7NEJTUU4lp1+AAxPgzPXR9qydoOlECBovp8OFEPek0gx40rVrVw4fPsyBAweMU5s2bRgyZAgHDhy4Y5IW5vdS53q809dw+eHLzaeZ8meE5bes8znUgA7fQfdwcG8HuakQ/48kaSFEuSpRZ7LyVq1aNZo2bWpS5ujoiLu7+03lwnI9G1oHW2stby07wqIdZ8jO0/Nuv6ZotRUk4XncZ0jW0T+AY6FbztIvwL/DIHAE1BwgCVwIUSYsOlGLymNI+wBsrbS8/tshftwZQ3aung8fbYZVRUnWGi3UveHWw5NfQtx60Gcbrm0LIUQZqHCJetOmTeYOQdylx9rUwtZay7hfDvLr3vNk5+qZ9XhzrK0s+grMrdX7D+hzwbNDQVnmJdg3DgJHGlri0soWQtyjCpeoRcXWr0UNbK20jFmynxUHL5Kdq2fO4JbYWlfAZO3oDy3eNy079TWc+cEwubWEBqMgYDBYO5gnRiFEhVcBvx1FRdcz2Jf5T7XG1krLmqNxvPTDXjJzLOfRqPfErxfUfdYwrvi1/bDzP7C8Jux7DVJOmTs6IUQFJIlamEW3xt4sGNoGO2st/xxLoPecrWyMSjB3WPfOrTnc9w30Pw8tPgLHOpB9DY59DH8GwsZecOEvw9jiQghRDJKohdl0buDJwmfbUt3RllOX0nh24W6e+WYXx+MrwbCvdu7QeDz0PQGdV4JvD0BB7GrY3MeQtCNnQtZVc0cqhLBwFj3gSWmQAU8sX3JmDnP/Ock326PJyVNYaTU82c6f/z7UgOqOtuYOr/SknIQT8+DUN5CTaCizsoeHdkD1lmYNTQhRvirNgCeianC2t2FCryDW/bczYU28ydMrvv/3LJ1nbOTrrafJzq0kp4mr1YdWH8OAC9BuAbi1ADsvcC306NbEw5CXdctNCCGqHmlRC4sTfuoK01ZGEBGbDEAdD0f+r1cQ3YK8Ks7wo8WhFGTGg87HMK/PgT8CDLd8dd1geFCIEKJSkha1qNBC6rnz55j7+fDRYDyc7Ii+nMYL3+3hqf/tJPJ68q4UNJqCJA3Xe4VrDYOrVGtYUJ52zpDUhRBVkiRqYZGstBoGtfVn0/gujOxSD1trLdtPXqH3nK1M+P0wl1Mr4elhl0bQ7wx03QhW16/N6/NgfUf4Kwii5kB2kllDFEKUP0nUwqI52Vnzeo9GbBjXmd7NfNErWLIrhi4zNjF/8ymycivJ/df5tNbgElQwnxwJWVcgOQr2vgzLa8CuEZB4xHwxCiHKlSRqUSHUqu7A3CdbsfSlEJrVdCE1K5cPVh/joVlbWH04tuI8kaukXJvCgIvQZi44B0FuGpycD6uCYX1nOPuL4dq2EKLSks5kosLR6xXL9l/go7XHiE82nAJvV6c6k/o0pmkNFzNHV4aUgoRNcHwunF8O6vrZBJ0f1B9umHS+5oxQCFFMJclNkqhFhZWencv8zaf5cvMpsnL1aDQwsFVNxoc1xMvZ3tzhla3083DiSzi1wNBzHEBjbXiKV6Nx4NHevPEJIW5Len2LKsHB1ppxDzXgn9e60K+FH0rB0r3n6TJzE3M3nqw844cXxaEmNJ8G/WKgw4/gGQoqF2J+MTx6M1/l/h0uRJUgiVpUeDVcdXz6REt+H9mBFrVcSc/OY8baKLp+vJk/D16svNevwdA7vPZgeGgb9NwP9V4wPH4z3+lvYHVrw2hoQogKSRK1qDRa+buxbGQHPn2iBX4u9lxIzGDMkv0MnB/OgXOJ5g6v7Lm1gPZfgc67oOz8Cri2D9IvFJTlpMDFNTICmhAVhCRqUaloNBr6tajBhle7MO6hBuhsrNh79hr9525n3M8HiE3KMHeI5av9Amj/jaHVnS92DWzqCb+5w9ZH4fS3kHnJfDEKIW5LOpOJSi0uKZMZa6P4bd95AOxttLzUuR4vdqqHztbKzNGZyelFcPAtyLhYUKbRgkcI1HjYMDk3NIycJoQoE9LruxBJ1ALg0PlEpq2MYPeZawD4utjzeo+G9GteA622CiYkpQynxM+vgAt/wrX9psurBV5P2n0NHdW01uaJU4hKShJ1IZKoRT6lFKsOx/H+qkguJBpOgTev5cqkPo1pHeBm5ujMLC0GLqyECysgfiPoswuW2bpB00nQ6BWzhSdEZSO3ZwlRBI1GQ+9mvmx4tTOv92iIo60VB88l8ui8HYxZsp/z19LNHaL5OPpDg5HwwBp49DLc/yvUeQbs3CH7GthUK6ibdg6iPoPUM2YLV4iqRFrUospKSMnk47XH+WXvOZQCO2stL3Ssy4gu9XC0k1O9gOGhIJfDDeOP27kbyo59CvteAa8u0G1jQV2l5Lq2EMUkLWohisGrmj0fDmzGyjH3c1/d6mTl6vl840kemLmJpXvOoddX6t+wxaO1Aq/7C5I0GAZb8eoEtQYUlGXEw/KasPMFOP8n5FbhsxNClDKLTtTTp0+nbdu2VKtWDS8vL/r3709UVJS5wxKVTBM/F5a8cB9fPt2aAHcHElKyGP/rIR6eu42dp6+YOzzL4/8odNsMDccWlF1cZehFfupr2PIw/OYBm/vBya8hI858sQpRCVj0qe8ePXrwxBNP0LZtW3Jzc/m///s/jhw5QkREBI6OjsXahpz6FiWRlZvHtzvO8NmGk6Rk5QLQK9iHCT2DqFXdwczRWbC8LEjYXNCLPD3GdLl7e6h5/dYvlyZyilxUeZW21/elS5fw8vJi8+bNdOrUqVjrSKIWd+NyahafrDvOkl0x6BXYWml57v46jHqgHtXsbcwdnmVTChIPFSTtq7tNlzvWNiRs/4Hg1dEsIQphbiXJTRWqx0xSUhIA1atXv2WdrKwssrIKhkZMSUkp87hE5ePhZMd7A4J5OiSAd1dGsu3kZeZvPsXSPefo29yPPs18aeXvVjXvwb4TjQbcmhum4ImQfhEurjRcu45fD2ln4PgcyLpckKj1uZAcZei0prHoK3JClLsK06LW6/U8/PDDJCYmsm3btlvWmzx5MlOmTLmpXFrU4m4ppfjnWALv/RXJ6ctpxnIfZ3t6BvvQO1iSdrHlphme7nXhT6jRD2r2NZRf3Qtr2oBjADwcXXBqPDcDrHXmi1eIMlIpT32PGDGC1atXs23bttu+qRtb1BcuXKBx48aSqMU9y8nTsznqEqsOx7IuIt54DRskad+zc7/DjqcNvckfWF1Q/kcd0NqCx32GIU497gOXpjJSmqjwKl2iHj16NH/88QdbtmyhTp06JVpXrlGLspCVm8fW45dvm7T7NPOlZS1J2sWmzzUMrmLvaZjPvAS/e91cz8oB3NsWJG73+0yfGCZEBVBpErVSijFjxrBs2TI2bdpEYGBgibchiVqUtTsl7V7BvvRu5iNJ+25kXYHLO+HKv3D5X7iyE3KSb67nWLsgcQc8CfYe5R6qECVRaRL1yJEj+fHHH/njjz9o2LChsdzFxQWdrnjXrSRRi/KUn7T/OhzL+huStq+LPT2bStK+J0oPSZEFifvyv5B0FCj0NdbvjOFaN0DcP5B9BTw7SatbWJRKk6g1t7jXcuHChQwbNqxY25BELcwlMyePrScKWtqpkrTLRnaS4Rawy/8akniHHwo6o23pD+f/gJYfQ9A4Q1nmZUiJArdW0lFNmE2luT3Lgn9DCHFH9jZWPNTYm4cae9+UtGOTMvlmezTfbI8ulLR9aVnLVZJ2Sdm6gE83w3Qjl6aGJ4N5digoi10N4c+A1gZcW1zvqHZ9cqwjg7EIi2PRLerSIC1qYWnu1NLuFexLr2BJ2mXmxJdw+B3IjL95mb2XoXNafi/z6m3Axqn8YxSVXqU59V0aJFELS5aftP86dJH1kQkmSdvPxZ6ekrTLhlKQdvZ6B7V/DU8Iu7Yf9Dmm9TRacAmGWo9A8CTzxCoqJUnUhUiiFhVFZk4eW44b7tO+VdLOPz1+q/4b4h7kZcLV/Yaknd9ZLf2cYVntp6HDd4bX+hxYex9UC4T2Xxe0uOUxn6IEKs01aiGqEnsbK7o38aF7Ex+TpL0uIp6LSZn8b1s0/9sWjV/+6XFJ2qXLyh48QwxTvvQLhoSt8y0oSzkF1/YZOqRZF3o40PZBhhHWnIMMQ6E6X59cGoGtW/m9D1HpSItaCAuXn7Tzb/lKy84zLpOkbQY5KZCwxXCPd91nCsr/agJJEUWvY+9dKIE3KnitqyGt8CpKTn0XIolaVCaZOXlszj89fkPSruGqo2dTH0na5pIRB8mRkHzMcJtYcqTh34wLt16n6TvQbLLhdfY1iN8MLo3BuUG5hCzMR059C1FJ2dtYEdbEh7Drp8cLJ+0LiRl8vS2ar7dFU8NVR9cgL4JruNC0hguBXk5YW8lTqcqUzscweT9gWp6TYpq885N5yknThHxlN2wdYGht9ynUMj8xD6ydr7fGG5qebhdVgiRqISqoOyXt78LPGuvaWWtp5OtMUz9nmtZwoamfCw18nLCztjLjO6gibKoZxiZ3b2tanpcN6AvmlTIMwuLS2LRs/xuQW+hxvY4BpqfP86+Fy7CplZac+haikslP2ruir3LkQhIRF5NNhjLNZ63V0MC7Gk1rOBNcw4UmNVwI8nFGZyvJ22LkZsC+Vwpa5FmXbl3Xzr0gaTccA67BhnKll2d8WyC5Rl2IJGpR1en1ipir6Ry5mMSRC8kcvZjE4QtJJKbn3FRXq4H6Xk409TMk7qZ+zjT2c6aavY0ZIhc3ybpS6BR6odPpaWcxGe+82xbw6mh4ffwLODgB6gyDNp8aypSCM4vBoRY41gJdTbCyLe93U6XJNWohhJFWq6G2hyO1PRzp08wPMAzPeyExw5i4j1xI4vCFZC6nZnE8PpXj8an8vr+gE1RdD0dj4m5aw4Umfs64OsgXe7mzcwev+w1TYbnpkHK8IHG7Ni1Yln7u+hPHCiXyrCsQ/nShDWgMPdMd/Q3J28HfkMAdrs87+htGbZOWuVlIi1oIYZSQnGlseR++kMTRC0lcTMossm5NNx1N/VxoWuP6de8aLng42ZVzxOKOctMM451b6cCptqEsLQb+fdaQxNNiQJ915+1obeGhbQXX2i/vhGsHwL0NVG9dVtFXWtKiFkLcFS9nex50tufBRgWPhLySmsXRi8kcuZjE0QuGf89eSef8tQzOX8tgzdE4Y10fZ3ua1nCmiZ/L9eTtjI+zvdwqZk7WjoZOZ4U5+kPXDYbXSkHWZUiPgbRzhn/zE3j+v5mxoM82tLrznV8OER9AgzEFiTrrCqzvUtAyv7GFLqfY74okaiHEbbk72dGpgSedGngay5IycjhaKHEfuZDE6ctpxCVnEpecyfrIBGNdDyfb64nb+XoL3IWabjpJ3pZCowF7T8N0q5axPgcyLhoGaMnn3BD8+hgeXJIv7SwkHTFMRe+s0Cn2Qsm87jCwdTVUycsEjQ1opVNjPjn1LYQoFWlZuUTGJnPkQhJHLhr+PZGQSp7+5q8YZ3tr4+nyJn7O1PN0ws9Vh5uDjSTwiiwn2TDkalpM0S3zW51i738OHK5/P+97DaI+gSZvQbOphrLMS3B4suE6ud31HxV2XgX/2lWvcNfP5dS3EKLcOdpZ06Z2ddrUrm4sy8zJ41hcCkcuJF3vtJZMVFwKyZm57Dh1hR2nrphsw95Gi5+LDl9Xe3xddPi56vBzsTf8e73M0U6+tiyWjTP4di962S1PsZ81JN98WZcMt5RZF3q8aPo5OPHFrfer0YKdx/Ukfj2Z23lC04mgu366Pu0c5KaCQw1DnBWItKiFEOUqO1fPiYQUk9PmMVczuJxajA5NgIvOBl8Xe2q4FiT0Gq46fK8ndB8Xe2xkFLaKS59juNZtZVfwMJO0s3Dya8hKMLSusy5BZoLh3+xrt95W/wvgYLjTgb3jDC31oPHQ8iNDWfpFQ+/3G1vphZO9vZfhtHwpt9ilRS2EsFi21lqa+LnQxM+Fx6llLM/KzSM+KYsLiRnEJmVwMTGDi0mZxCZmcDExk4tJGaRk5pKUkUNSRg7H4lKK3L5GA55Odiat8MItc19Xezwc7eT53pZKa2MYirUwxwBoPq3o+vocQ0s989LNidyu0GhtGi3YuBoSb76MixD/z51j0lgZtuXRATr9XuK3dK8kUQshLIKdtRX+7g74uzvcsk5KZg6xSZmGZJ6YSWxShvH1xaQMYpMyyc7Vk5CSRUJKFgfOFb0dWystPi72RbfMXQ0J3VkGeakYtDaGx5AWfhRpUVrNNEyFTyI71oYOiwta54WTfX5ZThKoPMiMv33rvQxJohZCVBjV7G2oZm9DA+9qRS5XSnElLdvQGk/M5KKxdX49kSdmEp+SSXaenpir6cRcTb/lvpzsrI2n0/Nb5r4u9lR3tMVFZ2OYHAz/ypjpFUjhzor2HlD7ydvXz8u63mJPMFuHNUnUQohKQ6PR4OFkh4eTHc1ucdkvJ09PfHImF6+3yAsn9AvXyxLTc0jNyuVEQionElLvuF97Gy0uOhtcdYYk7nw9kbteT+Q3JvbCk1xPt3BWdoYOaA417ly3jEiiFkJUKTZWWmq6OVDT7dan2NOzcwsl8oJkHpecSWJ6jvE6eXJmDkpBZo6ezJws4pOL1yGuMEdbq+tJ3BYXnbUxgbs63JD0b0jwzjobrOQ6e5UgiVoIIW7gYGtNfS8n6ns53baeXq9MOrglZmQbXydl5JBUKKknZeQYk3xyRo7xiWZp2XmkZefdcqjW26lmXzixmyZxZ3sbHGyt0NlYobO1wt7Gyjhvf71MZ1Ow3M5aK/ewW6gKkajnzp3LjBkziIuLo3nz5nz22We0a9fO3GEJIao4rVZjOJ3tUPKOZ7l5epILJXlDIs8muYjEfuOUnp0HQEpmLimZuZy/lnHP70WjAXtrQzK/MZHb21qhs9Eak7rOxhqdrbbIpG9va4VDoTL7G17LWYCSs/hE/fPPPzNu3Djmz59P+/btmT17NmFhYURFReHl5XXnDQghhAWyttJS3dGW6o4lH/s6O1dPcqZpCz0/0Sdl5BpPy2fm5JGZk0d6dh4ZOXlkZBvmC17ryc7TA4bO0BnXl5UlW2tDgi/curez0WJjpcXWSouNlQYbKy021jfM3/Da1vqGeSstNtY3zOevY10wb22lueUyS/0RYfEDnrRv3562bdvy+eefA6DX66lVqxZjxozhzTffvOP6MuCJEELcWm6ensxcPRnZhuSdkVN0Us+4nvQzsvNIv93yQj8C0rNzr5frzf02i0WroVDSL/ghYEzs1hrqeTrx6RMt73lflWbAk+zsbPbu3cuECROMZVqtlm7duhEeHm7GyIQQonKwttLiZKXFqQyHZtXrFVm5+iJ/BKRn55GVk0euXpGTpyc7V09OnuF1Tp6hxZ+Te8N8obL8+dw8VbAsr/C2btheoe3n3jAOvV5BVq6erFw9lLxfYJmx6ER9+fJl8vLy8Pb2Nin39vbm2LFjRa6TlZVFVlbBEU5JKXr0IiGEEOVDq9UYrlPbWtb95nq9IkdvSNy5xqSvyMkt/KPgepLPNczrbMr/PVh0or4b06dPZ8qUKeYOQwghhIXTajXYaa2w9Oe8WPSd9h4eHlhZWREfH29SHh8fj4+PT5HrTJgwgaSkJOMUERFRHqEKIYQQZcKiE7WtrS2tW7dmw4YNxjK9Xs+GDRsICQkpch07OzucnZ2NU7VqRQ81KIQQQlQEFt7gh3HjxjF06FDatGlDu3btmD17NmlpaTz77LPmDk0IIYQocxafqAcNGsSlS5eYNGkScXFxtGjRgjVr1tzUwUwIIYSojCw+UQOMHj2a0aNHmzsMIYQQotxViER9L/R6w432sbGxZo5ECCGEMMjPSfk56nYqfaLO7zEuY4MLIYSwNPHx8fj7+9+2jsUPIXqvcnNz2b9/P97e3mi199bJPSUlhcaNGxMRESG9yYUQooopzRyg1+uJj4+nZcuWWFvfvs1c6RN1aUpOTsbFxYWkpCScnZ3NHY4QQohyZK4cYNH3UQshhBBVnSRqIYQQwoJJoi4BOzs73nnnHezs7MwdihBCiHJmrhwg16iFEEIICyYtaiGEEMKCSaIWQgghLJgkaiGEEMKCSaIugblz51K7dm3s7e1p3749u3btMndIQgghytiWLVvo27cvfn5+aDQali9fXq77l0RdTD///DPjxo3jnXfeYd++fTRv3pywsDASEhLMHZoQQogylJaWRvPmzZk7d65Z9i+9voupffv2tG3bls8//xwwDP9Wq1YtxowZw5tvvmnm6IQQQpQHjUbDsmXL6N+/f7ntU1rUxZCdnc3evXvp1q2bsUyr1dKtWzfCw8PNGJkQQojKThJ1MVy+fJm8vDy8vb1Nyr29vYmLizNTVEIIIaoCSdRCCCGEBZNEXQweHh5YWVkZn22dLz4+Hh8fHzNFJYQQoiqQRF0Mtra2tG7dmg0bNhjL9Ho9GzZsICQkxIyRCSGEqOxu/7RqYTRu3DiGDh1KmzZtaNeuHbNnzyYtLY1nn33W3KEJIYQoQ6mpqZw8edI4Hx0dzYEDB6hevTr+/v5lvn+5PasEPv/8c2bMmEFcXBwtWrRgzpw5tG/f3txhCSGEKEObNm3igQceuKl86NChLFq0qMz3L4laCCGEsGByjVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIUeo0Gg3Lly83dxhCVAqSqIWoZIYNG4ZGo7lp6tGjh7lDE0LcBXkohxCVUI8ePVi4cKFJmZ2dnZmiEULcC2lRC1EJ2dnZ4ePjYzK5ubkBhtPS8+bNo2fPnuh0OurWrcuvv/5qsv7hw4d58MEH0el0uLu7M3z4cFJTU03qfPPNNzRp0gQ7Ozt8fX0ZPXq0yfLLly8zYMAAHBwcCAwMZMWKFcZl165dY8iQIXh6eqLT6QgMDLzph4UQwkAStRBV0MSJE3n00Uc5ePAgQ4YM4YknniAyMhKAtLQ0wsLCcHNzY/fu3SxdupT169ebJOJ58+YxatQohg8fzuHDh1mxYgX169c32ceUKVN4/PHHOXToEL169WLIkCFcvXrVuP+IiAhWr15NZGQk8+bNw8PDo/wOgBAViRJCVCpDhw5VVlZWytHR0WR67733lFJKAeqll14yWad9+/ZqxIgRSimlvvrqK+Xm5qZSU1ONy//66y+l1WpVXFycUkopPz8/9dZbb90yBkC9/fbbxvnU1FQFqNWrVyullOrbt6969tlnS+cNC1HJyTVqISqhBx54gHnz5pmUVa9e3fg6JCTEZFlISAgHDhwAIDIykubNm+Po6GhcHhoail6vJyoqCo1Gw8WLF+natettY2jWrJnxtaOjI87OziQkJAAwYsQIHn30Ufbt20f37t3p378/HTp0uKv3KkRlJ4laiErI0dHxplPRpUWn0xWrno2Njcm8RqNBr9cD0LNnT86ePcuqVatYt24dXbt2ZdSoUcycObPU4xWiopNr1EJUQf/+++9N80FBQQAEBQVx8OBB0tLSjMu3b9+OVqulYcOGVKtWjdq1a7Nhw4Z7isHT05OhQ4fyww8/MHv2bL766qt72p4QlZW0qIWohLKysoiLizMps7a2NnbYWrp0KW3atOH+++9n8eLF7Nq1i//9738ADBkyhHfeeYehQ4cyefJkLl26xJgxY3j66afx9vYGYPLkybz00kt4eXnRs2dPUlJS2L59O2PGjClWfJMmTaJ169Y0adKErKwsVq5cafyhIIQwJYlaiEpozZo1+Pr6mpQ1bNiQY8eOAYYe2T/99BMjR47E19eXJUuW0LhxYwAcHBxYu3YtL7/8Mm3btsXBwYFHH32UWbNmGbc1dOhQMjMz+eSTT3jttdfw8PBg4MCBxY7P1taWCRMmcObMGXQ6HR07duSnn34qhXcuROWjUUopcwchhCg/Go2GZcuW0b9/f3OHIoQoBrlGLYQQQlgwSdRCCCGEBZNr1EJUMXK1S4iKRVrUQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQgghhAX7f79J3y4y6bbOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, 1, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced1f1b",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7273582",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d741c3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
